{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e94fef3",
   "metadata": {},
   "source": [
    "## Initial Data Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d4e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "SEED = 39\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32292fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f3422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.175161e-15</td>\n",
       "      <td>3.384974e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.094852e-15</td>\n",
       "      <td>1.021879e-15</td>\n",
       "      <td>1.494498e-15</td>\n",
       "      <td>-5.620335e-16</td>\n",
       "      <td>1.149614e-16</td>\n",
       "      <td>-2.414189e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628620e-16</td>\n",
       "      <td>-3.576577e-16</td>\n",
       "      <td>2.618565e-16</td>\n",
       "      <td>4.473914e-15</td>\n",
       "      <td>5.109395e-16</td>\n",
       "      <td>1.686100e-15</td>\n",
       "      <td>-3.661401e-16</td>\n",
       "      <td>-1.227452e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.175161e-15  3.384974e-16 -1.379537e-15  2.094852e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.021879e-15  1.494498e-15 -5.620335e-16  1.149614e-16 -2.414189e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.628620e-16 -3.576577e-16  2.618565e-16  4.473914e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.109395e-16  1.686100e-15 -3.661401e-16 -1.227452e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50668e2a",
   "metadata": {},
   "source": [
    "- Dataset consists of 31 quantititave variables, with the target being \"Class\". Notably, variables V1, V2, ..., V28 are principle components obtained with PCA already while feature \"Amount\" was kept for interpretation, which might introduce redundant scaling bias into the static model. Standardization for that particular feature might be needed to mitigate this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369a2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498889c",
   "metadata": {},
   "source": [
    "- Data is efficiently stored in float64 and int64 values, taking up 67.4 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7199b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "096ea7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    99.827251\n",
      "1     0.172749\n",
      "Name: proportion, dtype: float64\n",
      "1081\n"
     ]
    }
   ],
   "source": [
    "print(df.Class.value_counts(normalize=True) * 100)\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413d1a9",
   "metadata": {},
   "source": [
    "- As seen from this proportion, the positive events are extremely dominated by the negative events. To address this, methods like class weights and SMOTE might be implemented.\n",
    "- No null values but some duplications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228cf731",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f4b0c",
   "metadata": {},
   "source": [
    "### Duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487abcb3",
   "metadata": {},
   "source": [
    "- As observed in the Data Diagnosis phase, there are some duplicates in this dataset of credit card transaction. This is common as credit card holders can sometimes swipe twice or encounter errors with the credit card processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cca5b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(columns=[\"Time\"],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e82029",
   "metadata": {},
   "source": [
    "- Drop identical duplicates for reduced dataset bias and column \"Time\" to focus on static modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88df9e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f9faf",
   "metadata": {},
   "source": [
    "### Data Splitting, Stratefied Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5165f1",
   "metadata": {},
   "source": [
    "- When developing a ML model, dedicating partitions of the dataset exclusively for training and testing provides an opportunity to observe how well the model would perform with unseen real data, if deployed in real world.\n",
    "- Within the training processes, we further implement cross validation to ensure our trained model is not overfitting or underfitting to our limited training data. Stratefied Cross Validation is utilized to preserve class ratio given the imbalanced dataset.\n",
    "- For scoring metrics, we refer to threshold-free metrics like ROC AUC and PR AUC for testing the hypotheses in the Data Preprocessing Phase as the final threshold hasn't been decided yet. Had we chose metrics from the confusion matrix of the default threshold 0.5, we can be completely biased into designing a pipeline that optimizes for the threshold 0.5 only, not all of the possible values.\n",
    "    - As mentioned, due to the imbalance nature of this problem, a high ROC AUC score can be misleading as a low FPR can still indicate massive false positives due to the dominant negative class. This leads us to the Precision-Recall curve, which put a constraint context on minimizing type 1 and type 2 errors with respect to the true positives, so that the false positives doesn't blow out of proportion.\n",
    "    - Ideally, we want to maximize PR AUC score in this problem so that during the model selection phase, we can fix a constraint for recall and maximize precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47845dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "# Splitting the training/testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=SEED)\n",
    "# Define Stratified Cross Validation\n",
    "cv = StratifiedKFold(n_splits=5, \n",
    "                     shuffle=True, \n",
    "                     random_state=SEED)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring_metrics = {\n",
    "    'pr_auc': make_scorer(average_precision_score),\n",
    "}\n",
    "\n",
    "# Boilerplate code for displaying metrics\n",
    "def print_results(cv_results):\n",
    "    print(\"Out-of-fold predictions:\")\n",
    "    print(f\"Avg PR AUC: {np.mean(cv_results['test_pr_auc']):.4f} (+/- {np.std(cv_results['test_pr_auc']):.4f})\")\n",
    "\n",
    "    print(\"\\nIn-fold predictions:\")\n",
    "    print(f\"Avg PR AUC: {np.mean(cv_results['train_pr_auc']):.4f} (+/- {np.std(cv_results['train_pr_auc']):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af959bf9",
   "metadata": {},
   "source": [
    "### Scaling - Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823c235",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Hypothesis: Other scaling methods might outperform standardization for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd571ccc",
   "metadata": {},
   "source": [
    "- As mentioned above, standardization for feature \"Amount\" helps reduce model's bias and optimize the model fitting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f87250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-fold predictions:\n",
      "Avg PR AUC: 0.5340 (+/- 0.0334)\n",
      "\n",
      "In-fold predictions:\n",
      "Avg PR AUC: 0.5462 (+/- 0.0221)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale_amount', StandardScaler(), ['Amount']) # \n",
    "    ],\n",
    "    remainder='passthrough'  # keep all other columns untouched\n",
    ")\n",
    "\n",
    "\n",
    "# Define base model pipeline with StandardScaler\n",
    "pipe = Pipeline([\n",
    "    ('scaler', ct), # apply custom scaler\n",
    "    ('model', LogisticRegression(max_iter=1000)) # bypass warnings for default configure\n",
    "])\n",
    "\n",
    "# Obtain cross validation results\n",
    "cv_results = cross_validate(pipe, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=cv, \n",
    "                            scoring=scoring_metrics,\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Print the results\n",
    "print_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7e53a",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1511c",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Hypothesis: Removing outliers in the majority class only might improve the PR curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dec858",
   "metadata": {},
   "source": [
    "- No outliers detection or removal was done to preserve the scarce imbalanced data in this dataset. Any datapoint, may it be positive or negative, is crucial to the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047ddb9",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f974089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-fold predictions:\n",
      "Avg PR AUC: 0.0524 (+/- 0.0027)\n",
      "\n",
      "In-fold predictions:\n",
      "Avg PR AUC: 0.0543 (+/- 0.0037)\n"
     ]
    }
   ],
   "source": [
    "pipe_class_weight = Pipeline([\n",
    "    ('scaler', ct),\n",
    "    ('model', LogisticRegression(max_iter=1000, \n",
    "                                 class_weight='balanced'))\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(pipe_class_weight, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=cv, \n",
    "                            scoring=scoring_metrics,\n",
    "                            return_train_score=True)\n",
    "\n",
    "print_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8025441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-fold predictions:\n",
      "Avg PR AUC: 0.0496 (+/- 0.0019)\n",
      "\n",
      "In-fold predictions:\n",
      "Avg PR AUC: 0.0516 (+/- 0.0035)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as imbPipeline \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipe_smote = imbPipeline([\n",
    "    ('scaler', ct),\n",
    "    ('sampler', SMOTE(random_state=SEED)), \n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(pipe_smote, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=cv, \n",
    "                            scoring=scoring_metrics,\n",
    "                            return_train_score=True)\n",
    "\n",
    "print_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef6e11",
   "metadata": {},
   "source": [
    "- As seen from these results, implementing imbalance methods, like Class-Weighting and SMOTE, aren't effective for maximizing PR AUC for this Fraud Detection System. The main reason being that these methods improve the ROC AUC but also simultaneously flag a lot of nearby positive outliers to be positive as well, hence the abundance of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b19bd",
   "metadata": {},
   "source": [
    "### Polynomial and Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d4850",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Hypothesis: To maximize model performance while maintaining the algorithm's computing feasibility, the optimal maximum degree of polynomial is 2.\n",
    "    - Comment: 2 is enough to ensure model complexity is causing overfitting, with 86% average ROC AUC score for the training folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3920cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-fold predictions:\n",
      "Avg PR AUC: 0.6325 (+/- 0.0560)\n",
      "\n",
      "In-fold predictions:\n",
      "Avg PR AUC: 0.8583 (+/- 0.0072)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipe_poly = Pipeline([\n",
    "    ('scaler', ct),\n",
    "    ('poly', PolynomialFeatures(degree=2, \n",
    "                                include_bias=False)),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(pipe_poly, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=cv, \n",
    "                            scoring=scoring_metrics,\n",
    "                            return_train_score=True)\n",
    "\n",
    "print_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4b379",
   "metadata": {},
   "source": [
    "- As expected, adding polynomial features increases the model complexity but it's also prone to overfitting. The next steps in the model selection phase implement regularization and hyperparameter tuning to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627e9c8",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d738918",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14edc850",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Hypothesis: Is grid search the most optimal algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d411ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_results(gs_results):\n",
    "    best_index = gs_results.best_index_\n",
    "    cv_results = gs_results.cv_results_\n",
    "    print(\"Out-of-fold predictions (for best parameter):\")\n",
    "    for scorer in gs_results.scorer_:\n",
    "        print(f\"Avg {scorer}: \\t{cv_results[f'mean_test_{scorer}'][best_index]:.4f} (+/- {cv_results[f'std_test_{scorer}'][best_index]:.4f})\")\n",
    "\n",
    "    print(\"\\nIn-fold predictions (for best parameter):\")\n",
    "    for scorer in gs_results.scorer_:\n",
    "        print(f\"Avg {scorer}: \\t{cv_results[f'mean_train_{scorer}'][best_index]:.4f} (+/- {cv_results[f'std_train_{scorer}'][best_index]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "769ec92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best C parameter: {'model__C': np.float64(0.01)}\n",
      "Best PR AUC score: 0.6450\n",
      "Out-of-fold predictions (for best parameter):\n",
      "Avg pr_auc: \t0.6450 (+/- 0.0405)\n",
      "\n",
      "In-fold predictions (for best parameter):\n",
      "Avg pr_auc: \t0.7790 (+/- 0.0065)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_poly = Pipeline([\n",
    "    ('scaler', ct),\n",
    "    ('poly', PolynomialFeatures(degree=2, \n",
    "                                include_bias=False)),\n",
    "    ('model', LogisticRegression(max_iter=1000,\n",
    "                                 penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': np.logspace(-3, 2, 6)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe_poly,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='pr_auc',\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    "    n_jobs=10 # Depends on your machine RAM, adjust this number accordingly\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best C parameter: {grid_search.best_params_}\")\n",
    "print(f\"Best PR AUC score: {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "print_grid_search_results(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f0a37",
   "metadata": {},
   "source": [
    "- It seems that for Logistic Regression, this value of PR AUC of 64.5% is approaching the upper limit of the model capabilities. We can finalize the model by finding the best threshold next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfa545",
   "metadata": {},
   "source": [
    "### Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38a88b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold (from CV): 0.0176\n",
      "Max F3-Score (on CV):    0.8248\n",
      "Precision at Threshold (on CV): 0.6414\n",
      "Recall at Threshold (on CV):  0.8519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "BETA = 3  # Adjust this constant to emphasize recall better\n",
    "\n",
    "best_c = LogisticRegression(max_iter=1000,\n",
    "                            penalty='l2',\n",
    "                            C=0.01)\n",
    "\n",
    "y_cv_scores = cross_val_predict(best_c, \n",
    "                                X_train, \n",
    "                                y_train, \n",
    "                                cv=cv,\n",
    "                                method=\"predict_proba\")[:,1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_cv_scores)\n",
    "p = precision[:-1]\n",
    "r = recall[:-1]\n",
    "\n",
    "fbeta_scores = (1 + BETA**2) * (p * r) / ((BETA**2 * p) + r)\n",
    "fbeta_scores = np.nan_to_num(fbeta_scores, nan=0.0)\n",
    "\n",
    "best_idx = np.argmax(fbeta_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_fbeta = fbeta_scores[best_idx]\n",
    "best_precision = p[best_idx]\n",
    "best_recall = r[best_idx]\n",
    "\n",
    "print(f\"Optimal Threshold (from CV): {best_threshold:.4f}\")\n",
    "print(f\"Max F{BETA}-Score (on CV):    {best_fbeta:.4f}\")\n",
    "print(f\"Precision at Threshold (on CV): {best_precision:.4f}\")\n",
    "print(f\"Recall at Threshold (on CV):  {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37961835",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc482d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditCardFraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
